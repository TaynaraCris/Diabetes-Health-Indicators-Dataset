{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "675d0f22",
   "metadata": {},
   "source": [
    "# ETL Silver to Raw\n",
    "\n",
    "Nesta etapa, importamos as bibliotecas necessárias e definimos as credenciais de conexão com o banco de dados PostgreSQL (diabetes_health)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ee51a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_batch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DB_CONFIG = {\n",
    "    'host': 'localhost',\n",
    "    'port': 5432,\n",
    "    'database': 'diabetes_health',\n",
    "    'user': 'postgres',\n",
    "    'password': 'postgres'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b22002d",
   "metadata": {},
   "source": [
    "# Conexão e Limpeza do Ambiente (Gold)\n",
    "\n",
    "Antes de iniciar a carga, conectamos ao banco e executamos um TRUNCATE em todas as tabelas do schema dw. Isso garante que não haverá duplicidade de dados e que as chaves substitutas (SRKs) serão reiniciadas corretamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1f4944f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Limpando tabelas Gold (Truncate) para evitar duplicidade...\n"
     ]
    }
   ],
   "source": [
    "conn = psycopg2.connect(**DB_CONFIG)\n",
    "cur = conn.cursor()\n",
    "\n",
    "print(\"1. Limpando tabelas Gold (Truncate) para evitar duplicidade...\")\n",
    "tables = [\n",
    "    'dw.fat_saude_pessoa', \n",
    "    'dw.dim_demografia', \n",
    "    'dw.dim_estilo_vida', \n",
    "    'dw.dim_acesso_medico', \n",
    "    'dw.dim_historico_clinico'\n",
    "]\n",
    "for t in tables:\n",
    "    cur.execute(f\"TRUNCATE TABLE {t} CASCADE;\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41aaed15",
   "metadata": {},
   "source": [
    "# Leitura da Camada Silver\n",
    "\n",
    "Carregamos os dados tratados da tabela silver.diabetes_indicators para um DataFrame do Pandas. Estes dados já passaram pelo tratamento de outliers na etapa anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57b51542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. Lendo dados da Silver...\n"
     ]
    }
   ],
   "source": [
    "# 3. LEITURA DA SILVER\n",
    "print(\"2. Lendo dados da Silver...\")\n",
    "df = pd.read_sql_query(\"SELECT * FROM silver.diabetes_indicators\", conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3401ba1b",
   "metadata": {},
   "source": [
    "# Carga da Dimensão Demografia (dmg)\n",
    "\n",
    "Selecionamos as colunas demográficas distintas, geramos a chave substituta (dmg_srk) e inserimos na tabela dw.dim_demografia.\n",
    "\n",
    "Mapeamento: sex_desc → dmg_sex, age_group → dmg_ida, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c3aa785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Processando Demografia (dmg)...\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 4. DIMENSÃO DEMOGRAFIA (Mnemônico: dmg)\n",
    "# ---------------------------------------------------------\n",
    "print(\"3. Processando Demografia (dmg)...\")\n",
    "\n",
    "cols_dmg_origem = ['sex_desc', 'age_group', 'education_level', 'income_level_raw']\n",
    "df_dmg = df[cols_dmg_origem].drop_duplicates().reset_index(drop=True)\n",
    "df_dmg['dmg_srk'] = df_dmg.index + 1 # Gerar Surrogate Key\n",
    "\n",
    "dados_dmg = df_dmg[['dmg_srk', 'sex_desc', 'age_group', 'education_level', 'income_level_raw']].values.tolist()\n",
    "execute_batch(cur, \"\"\"\n",
    "    INSERT INTO dw.dim_demografia (dmg_srk, dmg_sex, dmg_ida, dmg_esc, dmg_ren) \n",
    "    VALUES (%s, %s, %s, %s, %s)\n",
    "\"\"\", dados_dmg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac766c5",
   "metadata": {},
   "source": [
    "# Carga da Dimensão Estilo de Vida (est)\n",
    "\n",
    "Processamos as informações sobre hábitos do paciente (fumo, alimentação, atividades físicas), geramos a est_srk e carregamos na tabela dw.dim_estilo_vida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4689ecd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. Processando Estilo de Vida (est)...\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 5. DIMENSÃO ESTILO DE VIDA (Mnemônico: est)\n",
    "# ---------------------------------------------------------\n",
    "print(\"4. Processando Estilo de Vida (est)...\")\n",
    "\n",
    "cols_est_origem = ['smoker', 'eats_fruits', 'eats_veggies', 'physical_activity', 'heavy_alcohol']\n",
    "df_est = df[cols_est_origem].drop_duplicates().reset_index(drop=True)\n",
    "df_est['est_srk'] = df_est.index + 1\n",
    "\n",
    "dados_est = df_est[['est_srk'] + cols_est_origem].values.tolist()\n",
    "execute_batch(cur, \"\"\"\n",
    "    INSERT INTO dw.dim_estilo_vida (est_srk, est_fum, est_fru, est_veg, est_fis, est_alc) \n",
    "    VALUES (%s, %s, %s, %s, %s, %s)\n",
    "\"\"\", dados_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ff67ff",
   "metadata": {},
   "source": [
    "# Carga da Dimensão Acesso Médico (acs)\n",
    "\n",
    "Tratamos os dados referentes ao plano de saúde e acesso a checkups, criando a chave acs_srk e inserindo em dw.dim_acesso_medico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b209f8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5. Processando Acesso Médico (acs)...\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 6. DIMENSÃO ACESSO MÉDICO (Mnemônico: acs)\n",
    "# ---------------------------------------------------------\n",
    "print(\"5. Processando Acesso Médico (acs)...\")\n",
    "\n",
    "cols_acs_origem = ['has_healthcare', 'cant_afford_doctor', 'cholesterol_check']\n",
    "df_acs = df[cols_acs_origem].drop_duplicates().reset_index(drop=True)\n",
    "df_acs['acs_srk'] = df_acs.index + 1\n",
    "\n",
    "dados_acs = df_acs[['acs_srk'] + cols_acs_origem].values.tolist()\n",
    "execute_batch(cur, \"\"\"\n",
    "    INSERT INTO dw.dim_acesso_medico (acs_srk, acs_pla, acs_cus, acs_col) \n",
    "    VALUES (%s, %s, %s, %s)\n",
    "\"\"\", dados_acs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bbce92",
   "metadata": {},
   "source": [
    "# Carga da Dimensão Histórico Clínico (cli)\n",
    "\n",
    "Consolidamos o histórico de doenças (pressão alta, colesterol, AVC, etc.), geramos a cli_srk e salvamos em dw.dim_historico_clinico. Ao final, fazemos o COMMIT das dimensões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b9c7fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6. Processando Histórico Clínico (cli)...\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 7. DIMENSÃO HISTÓRICO CLÍNICO (Mnemônico: cli)\n",
    "# ---------------------------------------------------------\n",
    "print(\"6. Processando Histórico Clínico (cli)...\")\n",
    "\n",
    "cols_cli_origem = ['high_bp', 'high_chol', 'stroke', 'heart_disease_attack', 'diff_walking']\n",
    "df_cli = df[cols_cli_origem].drop_duplicates().reset_index(drop=True)\n",
    "df_cli['cli_srk'] = df_cli.index + 1\n",
    "\n",
    "dados_cli = df_cli[['cli_srk'] + cols_cli_origem].values.tolist()\n",
    "execute_batch(cur, \"\"\"\n",
    "    INSERT INTO dw.dim_historico_clinico (cli_srk, cli_pre, cli_col, cli_avc, cli_cor, cli_and) \n",
    "    VALUES (%s, %s, %s, %s, %s, %s)\n",
    "\"\"\", dados_cli)\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7ba013",
   "metadata": {},
   "source": [
    "# Construção e Carga da Tabela Fato (fat)\n",
    "\n",
    "Realizamos o cruzamento (merge) do DataFrame principal com os DataFrames das dimensões para recuperar as chaves substitutas (SRKs). Em seguida, selecionamos as métricas e carregamos tudo na tabela final dw.fat_saude_pessoa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f2d3102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7. Montando Fato (fat)...\n",
      "   -> Inserindo 224143 registros na Fato...\n",
      "==================================================\n",
      "ETL Silver -> Gold Concluído (Com Mnemônicos).\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# 8. TABELA FATO (Mnemônico: fat)\n",
    "# ---------------------------------------------------------\n",
    "print(\"7. Montando Fato (fat)...\")\n",
    "\n",
    "# Join para pegar os IDs (SRKs)\n",
    "df_fat = df.merge(df_dmg, on=cols_dmg_origem) \\\n",
    "           .merge(df_est, on=cols_est_origem) \\\n",
    "           .merge(df_acs, on=cols_acs_origem) \\\n",
    "           .merge(df_cli, on=cols_cli_origem)\n",
    "\n",
    "cols_fato_final = [\n",
    "    'dmg_srk', 'est_srk', 'acs_srk', 'cli_srk', # Chaves\n",
    "    'diabetes_status', \n",
    "    'bmi', \n",
    "    'general_health', \n",
    "    'mental_health_days', \n",
    "    'physical_health_days', \n",
    "    'risk_factors_count'\n",
    "]\n",
    "\n",
    "dados_fato = df_fat[cols_fato_final].values.tolist()\n",
    "\n",
    "print(f\"   -> Inserindo {len(dados_fato)} registros na Fato...\")\n",
    "execute_batch(cur, \"\"\"\n",
    "    INSERT INTO dw.fat_saude_pessoa (\n",
    "        dmg_srk, est_srk, acs_srk, cli_srk, \n",
    "        fat_dia, fat_imc, fat_sau, fat_men, fat_fis, fat_ris\n",
    "    ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "\"\"\", dados_fato, page_size=2000)\n",
    "\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"ETL Silver -> Gold Concluído (Com Mnemônicos).\")\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
